{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"THIS TESTER IS USING THE FOLLOWING:\n",
    "\n",
    "Dataset: \n",
    "Music21 corpus 'ryansMammoth'\n",
    "\n",
    "Testing features:\n",
    "*Merging two feature vectors using FeatureUnion and Pipelines.\n",
    "1) Notes frequency feature vector, ngrams = range of 1-2.\n",
    "2) Steps frequency feature vector, ngrams = bigrams and trigrams.\n",
    "\n",
    "Classifier: \n",
    "SVM\n",
    "\n",
    "Additional scikit modules:\n",
    "Cross validation, feature union, metrics\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "###############################################\n",
    "\n",
    "import music21\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_corpus(corpus):\n",
    "    \"\"\"Takes MIDI files and creates feature arrays to be used for training.\"\"\"\n",
    "\n",
    "    features = {}\n",
    "    notes_corpus, steps_corpus, outcomes = [], [], []\n",
    "\n",
    "    # Convert MIDI file to score and iterate over notes in score\n",
    "    # Save relevant individual Note attributes into list, including Note obj (used to calc interval) and name\n",
    "    for score in corpus:\n",
    "        score = music21.corpus.parse(score)\n",
    "        all_notes = \"\"\n",
    "        notes = []\n",
    "        for note in music21.alpha.theoryAnalysis.theoryAnalyzer.getNotes(score, 0):\n",
    "            if note == None:\n",
    "                pass\n",
    "            else:\n",
    "                notes.append(note)\n",
    "                all_notes += note.name + \" \"\n",
    "                \n",
    "        notes_corpus.append(all_notes)\n",
    "        \n",
    "        # Creates string of all steps in a score and appends to steps_corpus\n",
    "        all_steps = \"\"\n",
    "        for i in range(1, len(notes)):\n",
    "            interval = music21.interval.Interval(noteStart=notes[i-1], noteEnd=notes[i])\n",
    "            step = int((interval.cents)/100)\n",
    "            all_steps += str(step) + ' '\n",
    "\n",
    "        steps_corpus.append(all_steps)\n",
    "        \n",
    "        mode_at_measure_0 = music21.alpha.theoryAnalysis.theoryAnalyzer.getKeyAtMeasure(score, 0).mode\n",
    "        outcomes.append((mode_at_measure_0 == 'major'))\n",
    "\n",
    "    features['notes_freq'],features['steps_freq'] = notes_corpus, steps_corpus\n",
    "    return features, outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "\n",
    "    feature_vectorizer = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('notes', Pipeline([\n",
    "                ('selector', ItemSelector(key='notes_freq')),\n",
    "                ('tfidf', TfidfVectorizer(min_df=1, analyzer='word', stop_words=None, ngram_range=(1,2), token_pattern=r'\\w#?-?')),\n",
    "            ])),\n",
    "            ('steps', Pipeline([\n",
    "                ('selector', ItemSelector(key='steps_freq')),        \n",
    "                ('tfidf', TfidfVectorizer(min_df=1, analyzer='word', stop_words=None, ngram_range=(2, 3), token_pattern=r'\\d\\d?'))\n",
    "            ])),\n",
    "        ])\n",
    "\n",
    "    classifier = SVC()\n",
    "    \n",
    "    return feature_vectorizer, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(feature_vectorizer, classifier, features, outcomes):\n",
    "    \n",
    "    cv = cross_validation.StratifiedKFold(outcomes, 5)\n",
    "    feature_vectors = feature_vectorizer.fit_transform(features)\n",
    "    outcomes = np.ravel(outcomes)\n",
    "    \n",
    "    # Running into an issue here splitting dataset bc features is not a vectorized object\n",
    "    # yet, still a dictionary. Might need to keep vectorizer and classifier separated.\n",
    "    precision, recall = [], []\n",
    "\n",
    "    for training_data, testing_data in cv:\n",
    "        X_train = feature_vectors[training_data]\n",
    "        X_test = feature_vectors[testing_data]\n",
    "        y_train = outcomes[training_data]\n",
    "        y_test = outcomes[testing_data]\n",
    "        \n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_predicted = classifier.predict(X_test)\n",
    "        p,r,_,_ = metrics.precision_recall_fscore_support(y_test, y_predicted)\n",
    "        precision.append(p[1])\n",
    "        recall.append(r[1])\n",
    "    \n",
    "    return classifier, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_precision_recall(precision, recall):\n",
    "    print \"Precision: \", np.average(precision), '+/-', np.std(precision)\n",
    "    print \"Recall: \", np.average(recall), '+/-', np.std(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def predict(pipeline, validation_features):\n",
    "#     \"\"\"Takes notes_corpus as a list of test scores (each a string of notes).\"\"\"\n",
    "    \n",
    "#     predictions = pipeline.predict(validation_features)\n",
    "#     outcomes = validation_features['outcomes']\n",
    "#     print 'PREDICTION:', predictions\n",
    "#     print \"\"\n",
    "#     print 'ACTUAL OUTCOMES: ', outcomes\n",
    "    \n",
    "#     count = 0\n",
    "#     for i in range(len(predictions)):\n",
    "#         if predictions[i] == outcomes[i]:\n",
    "#             count +=1\n",
    "        \n",
    "#     print '{} correct predictions out of {} sample test files'.format(count, len(outcomes))\n",
    "#     print float(count)/len(outcomes) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------Executable Code --------------------------------\n",
    "\n",
    "# Read test files and construct feature and outcome datasets\n",
    "scores = music21.corpus.getComposer('ryansMammoth')\n",
    "features, outcomes = build_feature_corpus(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.824365747977 +/- 0.00143330832899\n",
      "Recall:  1.0 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Train classifier using Kfold to split training vs. validation data, \n",
    "# and calculate precision vs. recall\n",
    "feature_vectorizer, classifier = build_pipeline()\n",
    "trained_pipeline, precision, recall = train_classifier(feature_vectorizer, classifier, features, outcomes)\n",
    "show_precision_recall(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
