{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"THIS TESTER IS USING LOGISTIC REGRESSION TO NOTES AND STEPS FEATURE VECTORS.\n",
    "\n",
    "Testing feature mergeing using FeatureUnion and Pipelines.\n",
    "    Notes frequency feature vectors are using the latest trial of ngrams = range of 1-2.\n",
    "    Steps frequency is applied to bigrams and trigrams.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "###############################################\n",
    "\n",
    "import music21\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_feature_corpus(filenames):\n",
    "    \"\"\"Takes MIDI files and creates feature arrays to be used for training.\"\"\"\n",
    "\n",
    "    features = {}\n",
    "    notes_corpus, steps_corpus, mode_corpus = [], [], []\n",
    "\n",
    "    # Iterating through every other file; for early trials using 1/2 files as training set, and other 1/2 to test\n",
    "    for filename in filenames:\n",
    "\n",
    "        # Convert MIDI file to score and iterate over notes in score\n",
    "        # Save relevant individual Note attributes into list, including Note obj (used to calc interval) and name\n",
    "        score = music21.converter.parse('MIDI test files/Cello solos/' + filename)\n",
    "        note_attributes = []\n",
    "        for note in music21.alpha.theoryAnalysis.theoryAnalyzer.getNotes(score, 0):\n",
    "            if note == None:\n",
    "                pass\n",
    "            else:\n",
    "                note_attributes.append([note, note.name])\n",
    "        print \"Note attributes for file {} completed\".format(filename)\n",
    "\n",
    "        # Creates string of all notes in a score and appends to notes_corpus\n",
    "        all_notes = \"\"\n",
    "        for note in note_attributes:\n",
    "            all_notes += note[1] + \" \"\n",
    "\n",
    "        notes_corpus.append(all_notes)\n",
    "\n",
    "        # Creates string of all steps in a score and appends to steps_corpus\n",
    "        all_steps = \"\"\n",
    "        for i in range(1, len(note_attributes)):\n",
    "            interval = music21.interval.Interval(noteStart=note_attributes[i-1][0], noteEnd=note_attributes[i][0])\n",
    "            step = int((interval.cents)/100)\n",
    "            all_steps += str(step) + ' '\n",
    "\n",
    "        steps_corpus.append(all_steps)\n",
    "\n",
    "        # Determines the mode (major or minor) and assigns to output corpus\n",
    "        # Note: At the moment, this doesn't take into account changes b/w major + minor w/in a score\n",
    "        mode_at_measure_0 = music21.alpha.theoryAnalysis.theoryAnalyzer.getKeyAtMeasure(score, 0).mode\n",
    "        is_major = (mode_at_measure_0 == 'major')\n",
    "        mode_corpus.append(is_major)\n",
    "\n",
    "    features['notes_freq'],features['steps_freq'], features['outcomes'] = notes_corpus, steps_corpus, mode_corpus\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_feature_vector_and_fit_model(features):\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion(\n",
    "            transformer_list=[\n",
    "                ('notes', Pipeline([\n",
    "                    ('selector', ItemSelector(key='notes_freq')),\n",
    "                    ('tfidf', TfidfVectorizer(min_df=1, analyzer='word', stop_words=None, ngram_range=(1,2), token_pattern=r'\\w#?-?')),\n",
    "                ])),\n",
    "                ('steps', Pipeline([\n",
    "                    ('selector', ItemSelector(key='steps_freq')),        \n",
    "                    ('tfidf', TfidfVectorizer(min_df=1, analyzer='word', stop_words=None, ngram_range=(2, 3), token_pattern=r'\\d\\d?'))\n",
    "                ])),\n",
    "            ])),\n",
    "                        \n",
    "        ('classifier', LogisticRegression()),\n",
    "        ])\n",
    "        \n",
    "    pipeline.fit(features_and_outcomes_dict, np.ravel(features_and_outcomes_dict['outcomes']))\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(pipeline, validation_features):\n",
    "    \"\"\"Takes notes_corpus as a list of test scores (each a string of notes).\"\"\"\n",
    "    \n",
    "    predictions = pipeline.predict(validation_features)\n",
    "    outcomes = validation_features['outcomes']\n",
    "    print 'PREDICTION:', predictions\n",
    "    print \"\"\n",
    "    print 'ACTUAL OUTCOMES: ', outcomes\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == outcomes[i]:\n",
    "            count +=1\n",
    "        \n",
    "    print '{} correct predictions out of {} sample test files'.format(count, len(outcomes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------Executable Code --------------------------------\n",
    "\n",
    "# read test files and construct training vs validation datasets\n",
    "filenames = open('test_files.txt').read().split('\\n')\n",
    "\n",
    "training_files = filenames[::2]\n",
    "validation_files = filenames[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note attributes for file cs1-1pre.mid completed\n",
      "Note attributes for file cs1-3cou.mid completed\n",
      "Note attributes for file cs1-5men.mid completed\n",
      "Note attributes for file cs2-1pre.mid completed\n",
      "Note attributes for file cs2-3cou.mid completed\n",
      "Note attributes for file cs2-5men.mid completed\n",
      "Note attributes for file cs3-1pre.mid completed\n",
      "Note attributes for file cs3-3cou.mid completed\n",
      "Note attributes for file cs3-5bou.mid completed\n",
      "Note attributes for file cs4-1pre.mid completed\n",
      "Note attributes for file cs4-3cou.mid completed\n",
      "Note attributes for file cs4-5bou.mid completed\n",
      "Note attributes for file cs5-1pre.mid completed\n",
      "Note attributes for file cs5-3cou.mid completed\n",
      "Note attributes for file cs5-5gav.mid completed\n",
      "Note attributes for file cs6-1pre.mid completed\n",
      "Note attributes for file cs6-3cou.mid completed\n",
      "Note attributes for file cs6-5gav.mid completed\n"
     ]
    }
   ],
   "source": [
    "# Build training features from input midi files\n",
    "features_and_outcomes_dict = build_feature_corpus(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = build_feature_vector_and_fit_model(features_and_outcomes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note attributes for file cs1-2all.mid completed\n",
      "Note attributes for file cs1-4sar.mid completed\n",
      "Note attributes for file cs1-6gig.mid completed\n",
      "Note attributes for file cs2-2all.mid completed\n",
      "Note attributes for file cs2-4sar.mid completed\n",
      "Note attributes for file cs2-6gig.mid completed\n",
      "Note attributes for file cs3-2all.mid completed\n",
      "Note attributes for file cs3-4sar.mid completed\n",
      "Note attributes for file cs3-6gig.mid completed\n",
      "Note attributes for file cs4-2all.mid completed\n",
      "Note attributes for file cs4-4sar.mid completed\n",
      "Note attributes for file cs4-6gig.mid completed\n",
      "Note attributes for file cs5-2all.mid completed\n",
      "Note attributes for file cs5-4sar.mid completed\n",
      "Note attributes for file cs5-6gig.mid completed\n",
      "Note attributes for file cs6-2all.mid completed\n",
      "Note attributes for file cs6-4sar.mid completed\n",
      "Note attributes for file cs6-6gig.mid completed\n"
     ]
    }
   ],
   "source": [
    "# Build features for validation data set of midi files.\n",
    "validation_features = build_feature_corpus(validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION: [ True  True  True False False False  True  True  True False False False\n",
      " False False False  True  True  True]\n",
      "\n",
      "ACTUAL OUTCOMES:  [True, True, True, False, False, False, True, True, True, False, True, False, False, False, False, False, True, True]\n",
      "16 correct predictions out of 18 sample test files\n"
     ]
    }
   ],
   "source": [
    "predict(pipeline, validation_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
